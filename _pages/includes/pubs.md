# üìù Selected Publications 
( <span class="equal">*</span> indicates equal contribution. Full list of  [<i class="fas fa-fw fa-graduation-cap"></i>publications](https://scholar.google.com/citations?hl=en&user=soDBSE8AAAAJ&view_op=list_works&sortby=pubdate))


<style>
.box {
  display: inline-block;
  background-color: lightgray;
}

.blue-text {
  color: blue;
}
</style>

<style>
  .equal {
    font-size: 20px;
  }
</style>
<style>
  .me {
    color:rgb(1, 9, 245);
    font-weight: bold;
  }
</style>

<style>
  .conf {
    color:rgb(146, 6, 45);
    font-weight: 600;
    font-size: 0.95em;
  }
</style>

<style>
  .resource-link {
    color: #333;
    padding: 6px 10px;
    border-radius: 5px;
    text-decoration: none;
    display: inline-block;
    margin: 4px 6px 4px 0;
    border: none;
    font-size: 0.9em;
    font-weight: 500;
    transition: all 0.2s ease;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.08);
  }

  .github-link {
    background-color: #f6f8fa;
    color: #24292e;
  }
  .github-link:hover {
    background-color: #e1e4e8;
    box-shadow: 0 3px 6px rgba(0, 0, 0, 0.12);
  }

  .blog-link {
    background-color: #e3f2fd;
    color: #1976d2;
  }
  .blog-link:hover {
    background-color: #bbdefb;
    box-shadow: 0 3px 6px rgba(25, 118, 210, 0.15);
  }

  .poster-link {
    background-color: #fce4ec;
    color: #c2185b;
  }
  .poster-link:hover {
    background-color: #f8bbd0;
    box-shadow: 0 3px 6px rgba(194, 24, 91, 0.15);
  }

  .paper-links {
    margin-top: 8px;
    margin-bottom: 8px;
  }

  .paper-title {
    font-weight: 600;
    margin-bottom: 6px;
    font-size: 1.02em;
    color: #003d82;
  }

  .paper-title a {
    color:rgb(4, 23, 1);
    text-decoration: none !important;
  }

  .paper-title a:hover {
    color:rgb(29, 222, 45);
  }

  .authors {
    margin-bottom: 8px;
    font-size: 0.95em;
    color: #333;
    line-height: 1.5;
  }

  .badge {
    display: inline-block;
    padding: 6px 12px;
    border-radius: 5px;
    font-size: 0.8em;
    font-weight: 700;
    color: white;
    background: linear-gradient(135deg, #003d82 0%, #004fa3 100%);
    margin-bottom: 10px;
    box-shadow: 0 2px 4px rgba(0, 61, 130, 0.2);
    letter-spacing: 0.3px;
  }

  .paper-box {
    margin-bottom: 10px;
    display: flex;
    background: linear-gradient(135deg, #fafbfc 0%, #f5f7fa 100%);
    border-radius: 8px;
    padding: 5px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
    transition: all 0.3s ease;
    border: 1px solid rgba(0, 61, 130, 0.1);
  }

  .paper-box:hover {
    box-shadow: 0 4px 12px rgba(0, 61, 130, 0.12);
    transform: translateY(-2px);
  }

  .paper-box-image {
    flex-shrink: 0;
    margin-right: 16px;
  }

  .paper-box-image img {
    border-radius: 6px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
  }

  .paper-box-text {
    flex: 1;
  }
</style>

<style>
  .pub-section-header {
    font-size: 1.1em;
    color: white;
    background: linear-gradient(135deg, #003d82 0%, #004fa3 100%);
    padding: 12px 16px;
    margin: 24px 0 16px 0;
    border-radius: 6px;
    font-weight: 700;
    letter-spacing: 0.5px;
    box-shadow: 0 2px 6px rgba(0, 61, 130, 0.15);
  }

  .coming-soon-box {
    background: linear-gradient(135deg, #fffef5 0%, #fff8e6 50%, #fff9f0 100%) !important;
    border: 3px dashed #ff7f00 !important;
    box-shadow: 0 0 15px rgba(255, 127, 0, 0.3), 0 4px 12px rgba(255, 127, 0, 0.15) !important;
    position: relative;
    padding: 4px !important;
  }

  .coming-soon-box::before {
    content: '';
    position: absolute;
    top: -8px;
    left: 20px;
    background: #ff7f00;
    color: white;
    padding: 2px 12px;
    border-radius: 10px;
    font-size: 0.8em;
    font-weight: 700;
    box-shadow: 0 2px 6px rgba(255, 127, 0, 0.3);
  }

  .coming-soon-box:hover {
    box-shadow: 0 0 20px rgba(255, 127, 0, 0.4), 0 6px 16px rgba(255, 127, 0, 0.25) !important;
    transform: translateY(-3px) !important;
  }

  .coming-soon-box .paper-title {
    color: #ff7f00 !important;
    font-size: 1.1em !important;
  }

  .coming-soon-box .paper-title a {
    color: #ff7f00 !important;
  }

  .coming-soon-box .authors {
    font-style: italic;
    color: #999;
  }

  .coming-soon-box .conf {
    color: #ff7f00 !important;
    font-weight: 600 !important;
  }

  .coming-soon-box .paper-box-image {
    display: flex !important;
    justify-content: flex-start !important;
    align-items: flex-start !important;
    flex-shrink: 1 !important;
    margin-right: 16px !important;
    padding-top: 8px !important;
  }

  .coming-soon-box .badge {
    margin-bottom: 0 !important;
    margin-top: -20px !important;
    margin-left: 8px !important;
    background: linear-gradient(135deg, #ff6b35 0%, #ff8c00 100%) !important;
    box-shadow: 0 0 10px rgba(255, 107, 53, 0.6), 0 0 20px rgba(255, 140, 0, 0.4) !important;
    border: 1px solid rgba(255, 255, 255, 0.3) !important;
    font-weight: 800 !important;
    letter-spacing: 0px !important;
  }

  details {
    margin: 24px 0;
  }

  details > summary {
    cursor: pointer;
    padding: 16px 20px;
    background: linear-gradient(135deg, #003d82 0%, #004fa3 100%);
    color: white;
    border-radius: 8px;
    font-weight: 700;
    font-size: 1.1em;
    letter-spacing: 0.5px;
    box-shadow: 0 2px 8px rgba(0, 61, 130, 0.2);
    transition: all 0.3s ease;
    display: flex;
    align-items: center;
    gap: 10px;
  }

  details > summary:hover {
    box-shadow: 0 4px 12px rgba(0, 61, 130, 0.3);
    transform: translateY(-2px);
    background: linear-gradient(135deg, #004fa3 0%, #005bb3 100%);
  }

  details > summary::before {
    content: '‚ñ∂';
    display: inline-block;
    transition: transform 0.3s ease;
    font-size: 0.8em;
  }

  details[open] > summary::before {
    transform: rotate(90deg);
  }

  details > ul {
    background: rgba(0, 61, 130, 0.02);
    border-left: 4px solid #003d82;
    border-radius: 0 8px 8px 0;
    padding: 20px 20px 20px 30px;
    margin-top: 8px;
    list-style: none;
  }

  details > ul > li {
    margin-bottom: 12px;
    padding: 8px 0;
    line-height: 1.6;
  }

  details > ul > li:last-child {
    margin-bottom: 0;
  }

  details > ul > li a {
    color: #003d82;
    font-weight: 600;
    text-decoration: none;
    transition: color 0.2s ease;
  }

  details > ul > li a:hover {
    color: #004fa3;
    text-decoration: underline;
  }
</style>




<div class="pub-section-header">üìö Preprint</div>


<div class='paper-box coming-soon-box'><div class='paper-box-image'><div><div class="badge">TBD <i class="fas fa-hourglass-end fa-spin"></i></div></div></div>
<div class='paper-box-text' markdown="1">
<span class="paper-title">üöÄ Something is Coming Soon‚Ñ¢ (Probably)  Status: <i class="fas fa-spinner fa-spin"></i> Thinking hard ü§î ...]</span>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">preprint</div><img src='images/black.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[Black-box Optimization of LLM Outputs by Asking for Directions](https://arxiv.org/abs/2510.16794)</span>

<span class="authors"><span class="me">Jie Zhang</span>, Meng Ding, Yang Liu, Jue Hong, Florian Tram√®r</span>

<!-- <span class="conf">[IEEE SP 2025, DLSP workshop]</span> -->
<a href="https://github.com/zj-jayzhang/black_box_llm_optimization" class="resource-link github-link"><i class="fab fa-github"></i> code</a>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE SP 2025, DLSP workshop</div></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[Position: Adversarial ML Problems Are Getting Harder to Solve and to Evaluate](https://arxiv.org/abs/2502.02260)</span>

<span class="authors">Javier Rando<span class="equal">*</span>, <span class="me">Jie Zhang</span><span class="equal">*</span>, Nicholas Carlini, Florian Tram√®r</span>

<span class="conf">[IEEE SP 2025, DLSP workshop]</span>

</div>
</div>





<!-- Accepted -->
<div class="pub-section-header">‚úÖ Accepted</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div><img src='images/realmath.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
<span class="paper-title">[RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics](https://arxiv.org/abs/2505.12575)</span>
  
<span class="authors"><span class="me">Jie Zhang</span>, Cezara Petrui, Kristina Nikoliƒá, Florian Tram√®r</span>
<div class="paper-links">
<a href="https://github.com/ethz-spylab/RealMath" class="resource-link github-link"><i class="fab fa-github"></i> code</a>
<a href="https://huggingface.co/datasets/ethz-spylab/RealMath" class="resource-link blog-link"><i class="fas fa-table"></i> dataset</a>
</div>
<span class="conf">[NeurIPS 2025, Dataset $\&$ Benchmark Track]</span>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/jailtax.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[The Jailbreak Tax: How Useful are Your Jailbreak Outputs?](https://arxiv.org/abs/2504.10694)</span>

<span class="authors">Kristina Nikoliƒá, Luze Sun, <span class="me">Jie Zhang</span>, Florian Tram√®r</span>

<div class="paper-links">
<a href="https://github.com/ethz-spylab/jailbreak-tax" class="resource-link github-link"><i class="fab fa-github"></i> code</a>
<a href="https://spylab.ai/blog/jailbreak-tax/" class="resource-link blog-link"><i class="fas fa-book"></i> blog</a>
</div>

<span class="conf">[ICML 2025, spotlight]</span>

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SaTML 2025</div><img src='images/position.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[Position: Membership Inference Attacks Cannot Prove that a Model Was Trained On Your Data](https://arxiv.org/abs/2409.19798)</span>

<span class="authors"><span class="me">Jie Zhang</span>, Debeshee Das, Gautam Kamath, Florian Tram√®r</span>

<div class="paper-links">
<a href="https://spylab.ai/blog/mia_position/" class="resource-link blog-link"><i class="fas fa-book"></i> blog</a>
<a href="posters/satml.pdf" class="resource-link poster-link"><i class="fas fa-file-pdf"></i> poster</a>
</div>

<span class="conf">[IEEE SaTML 2025]</span>


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CCS 2024</div><img src='images/mis.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[Evaluations of Machine Learning Privacy Defenses are Misleading](https://arxiv.org/abs/2404.17399)</span>

<span class="authors">Michael Aerni<span class="equal">*</span>, <span class="me">Jie Zhang</span><span class="equal">*</span>, Florian Tram√®r</span>

<div class="paper-links">
<a href="https://github.com/ethz-spylab/misleading-privacy-evals" class="resource-link github-link"><i class="fab fa-github"></i> code</a>
<a href="https://spylab.ai/blog/misleading-privacy-evals/" class="resource-link blog-link"><i class="fas fa-book"></i> blog</a> 
<a href="posters/ccs.pdf" class="resource-link poster-link"><i class="fas fa-file-pdf"></i> poster</a>
</div>

<span class="conf">[ACM CCS 2024]</span>


</div>
</div>





<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2025</div><img src='images/iclr25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[Does Training with Synthetic Data Truly Protect Privacy?](https://openreview.net/forum?id=C8niXBHjfO)</span>

<span class="authors">Yunpeng Zhao, <span class="me">Jie Zhang</span></span>

<div class="paper-links">
<a href="https://github.com/yunpeng-zhao/syndata-privacy" class="resource-link github-link"><i class="fab fa-github"></i> code</a>
</div>

<span class="conf">[ICLR 2025]</span>

</div>
</div>





<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE SP 2025, DLSP workshop</div><img src='images/blind_mia.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[Blind Baselines Beat Membership Inference Attacks for Foundation Models](https://arxiv.org/abs/2406.16201)</span>

<span class="authors">Debeshee Das, <span class="me">Jie Zhang</span>, Florian Tram√®r</span>

<div class="paper-links">
<a href="https://github.com/ethz-spylab/Blind-MIA" class="resource-link github-link"><i class="fab fa-github"></i> code</a>
<a href="posters/blind.pdf" class="resource-link poster-link"><i class="fas fa-file-pdf"></i> poster</a>
</div>

<span class="conf">[IEEE SP 2025, DLSP workshop]</span>

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/agentdojo.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class="paper-title">[AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents](https://arxiv.org/abs/2406.13352)</span>

<span class="authors">Edoardo Debenedetti, <span class="me">Jie Zhang</span>, Mislav Balunoviƒá, Luca Beurer-Kellner, Marc Fischer, Florian Tram√®r</span>

<div class="paper-links">
<a href="https://github.com/ethz-spylab/agentdojo" class="resource-link github-link"><i class="fab fa-github"></i> code</a>
<a href="posters/agentdojo.pdf" class="resource-link poster-link"><i class="fas fa-file-pdf"></i> poster</a>
</div>

<span class="conf">[NeurIPS 2024 Dataset $\&$ Benchmark Track]</span>


</div>
</div>
























<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='images/iclr24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Real-Fake: Effective Training Data Synthesis Through Distribution Matching](https://arxiv.org/abs/2310.10402) \\
Jianhao Yuan, <b>Jie Zhang</b>, Shuyang Sun, Philip Torr, Bo Zhao<sup>#</sup>. (ICLR 2024) \[[code](https://github.com/BAAI-DCAI/Training-Data-Synthesis)\]


- In this paper, through extensive experiments, we demonstrate the effectiveness of our synthetic data across diverse image classification tasks, both as a replacement for and augmentation to real datasets. Specifically, we achieve 70.9% top1 classification accuracy on ImageNet1K when training solely with synthetic data equivalent to 1 X the original real data size, which increases to 76.0% when scaling up to 10 X synthetic data.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022</div><img src='images/nips2022.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DENSE: Data-Free One-Shot Federated Learning](https://arxiv.org/abs/2112.12371) \\
<b>Jie Zhang<sup>*</sup></b>, Chen Chen<sup>*</sup>, Bo Li, Lingjuan Lyu, Shuang Wu, Shouhong Ding, Chunhua Shen, Chao Wu<sup>#</sup>. (NeurIPS 2022) \[[code](https://github.com/zj-jayzhang/DENSE )\]
- The paper focuses on one-shot federated learning, i.e., the server can learn a model with a single communication round. The proposed FedSyn method has two stages: first, training a generator from the ensemble of models from clients; second, distilling the knowledge of the ensemble into a global model with synthetic data. We validate the efficacy of FedSyn by conducting extensive experiments on 6 different datasets with various non-IID settings generated from Dirichlet distributions.
</div>
</div>  -->

<!-- Skip -->
<!-- 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023, highlight</div><img src='images/cvpr23.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">
[Accelerating Dataset Distillation via Model Augmentation](https://arxiv.org/abs/2212.06152) \\
  Lei Zhang<sup>*</sup>, <b>Jie Zhang</b><sup>*</sup>, Bowen Lei, Subhabrata Mukherjee, Xiang Pan, Bo Zhao, Caiwen Ding, Yao Li, Dongkuan Xu<sup>#</sup>. 
  (CVPR 2023) \[[code](https://github.com/zj-jayzhang/Acc-DD/ )\]

- In this paper, we assume that training the synthetic data with diverse models leads to better generalization performance. Thus we propose two model augmentation techniques, i.e., using early-stage models and weight perturbation to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20√ó speedup and comparable performance on par with state-of-the-art baseline methods.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='images/cvpr22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Towards Efficient Data-Free Black-box Adversarial Attack](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.html) \\
<b>Jie Zhang<sup>*</sup></b>, Bo Li<sup>*</sup>, Jianghe Xu, Shuang Wu, Shouhong Ding, Chao Wu<sup>#</sup>. (CVPR 2022)
\[[code](https://github.com/zj-jayzhang/Data-Free-Transfer-Attack )\]

- In this paper, by rethinking the collaborative relationship between the generator and the substitute model, we design a novel black-box attack framework. The proposed method can efficiently imitate the target model through a small number of queries and achieve high attack success rate.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2022</div><img src='images/icml22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Federated Learning with Label Distribution Skew via Logits Calibration](https://proceedings.mlr.press/v162/zhang22p.html) \\
<b>Jie Zhang</b>, Zhiqi Li, Bo Li, Jianghe Xu, Shuang Wu, Shouhong Ding, Chao Wu<sup>#</sup>. (ICML 2022) 

- In this work, we investigate the label distribution skew from a statistical view. We demonstrate both theoretically and empirically that previous methods based on softmax crossentropy are not suitable, which can result in local models heavily overfitting to minority classes and missing classes. Then, we propose FedLC (Federated learning via Logits Calibration), which calibrates the logits before softmax cross-entropy according to the probability of occurrence of each class.

</div>
</div>









<div style="margin-top: 40px; text-align: center;">
  <a href="/more/" style="display: inline-block; padding: 14px 28px; background: linear-gradient(135deg, #003d82 0%, #004fa3 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 700; font-size: 1.1em; box-shadow: 0 2px 8px rgba(0, 61, 130, 0.2); transition: all 0.3s ease;" onmouseover="this.style.boxShadow='0 4px 12px rgba(0, 61, 130, 0.3)'; this.style.transform='translateY(-2px)';" onmouseout="this.style.boxShadow='0 2px 8px rgba(0, 61, 130, 0.2)'; this.style.transform='translateY(0)';">
    üìç More: Talks, Honors & Awards, and More
  </a>
</div>
-->
